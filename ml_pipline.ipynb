{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ïä§ÌÇ§Îßà ÏÑ§Ï†ï\n",
    "Î∂àÎü¨Ïò¨ Îç∞Ïù¥ÌÑ∞Ïùò Ïä§ÌÇ§ÎßàÍ∞Ä ÏóÜÏùÑ Í≤ΩÏö∞ Î™®Îì† data typeÏù¥ StringÏúºÎ°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏùΩÏñ¥Ïò®Îã§. \n",
    "\n",
    "Ïù¥Îü∞ Î∂àÏÉÅÏÇ¨Î•º Î∞©ÏßÄÌïòÍ∏∞ ÏúÑÌï¥ Ïä§ÌÇ§ÎßàÎ•º ÏÑ§Ï†ïÌï¥ÎÜìÍ≥† Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨ÏôÄÎ≥¥Ïûê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Batsman: string (nullable = true)\n",
      " |-- Batsman_Name: string (nullable = true)\n",
      " |-- Bowler: string (nullable = true)\n",
      " |-- Bowler_Name: string (nullable = true)\n",
      " |-- Commentary: string (nullable = true)\n",
      " |-- Detail: string (nullable = true)\n",
      " |-- Dismissed: string (nullable = true)\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Isball: string (nullable = true)\n",
      " |-- Isboundary: string (nullable = true)\n",
      " |-- Iswicket: string (nullable = true)\n",
      " |-- Over: string (nullable = true)\n",
      " |-- Runs: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_schema_data = spark.read.csv('../data/ind-ban-comment.csv', header=True)\n",
    "non_schema_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Batsman: integer (nullable = true)\n",
      " |-- Batsman_Name: string (nullable = true)\n",
      " |-- Bowler: integer (nullable = true)\n",
      " |-- Bowler_Name: string (nullable = true)\n",
      " |-- Commentary: string (nullable = true)\n",
      " |-- Detail: string (nullable = true)\n",
      " |-- Dismissed: integer (nullable = true)\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Isball: boolean (nullable = true)\n",
      " |-- Isboundary: integer (nullable = true)\n",
      " |-- Iswicket: integer (nullable = true)\n",
      " |-- Over: double (nullable = true)\n",
      " |-- Runs: integer (nullable = true)\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_setting = tp.StructType([\n",
    "    tp.StructField(name='Batsman', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Batsman_Name', dataType=tp.StringType(), nullable=True),\n",
    "    tp.StructField(name='Bowler', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Bowler_Name', dataType=tp.StringType(), nullable=True),\n",
    "    tp.StructField(name='Commentary', dataType=tp.StringType(), nullable=True),\n",
    "    tp.StructField(name='Detail', dataType=tp.StringType(), nullable=True),\n",
    "    tp.StructField(name='Dismissed', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Id', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Isball', dataType=tp.BooleanType(), nullable=True),\n",
    "    tp.StructField(name='Isboundary', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Iswicket', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Over', dataType=tp.DoubleType(), nullable=True),\n",
    "    tp.StructField(name='Runs', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Timestamp', dataType=tp.TimestampType(), nullable=True)    \n",
    "])\n",
    "\n",
    "# read the data again with the defined schema\n",
    "data = spark.read.csv('../data/ind-ban-comment.csv', schema=schema_setting, header=True)\n",
    "\n",
    "# print the schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÌïÑÏöîÏóÜÎäî Ïª¨Îüº Ï†úÍ±∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+------+---------+------+----------+--------+----+----+---------+\n",
      "|     Batsman_Name|       Bowler_Name|          Commentary|Detail|Dismissed|Isball|Isboundary|Iswicket|Over|Runs|Timestamp|\n",
      "+-----------------+------------------+--------------------+------+---------+------+----------+--------+----+----+---------+\n",
      "|   Mohammed Shami| Mustafizur Rahman|OUT! Bowled! 5-fe...|     W|    28994|  true|      null|       1|49.6|   0|     null|\n",
      "|Bhuvneshwar Kumar| Mustafizur Rahman|WIDE AND RUN OUT!...|  W+wd|     5132|  true|      null|       1|49.6|   1|     null|\n",
      "|   Mohammed Shami| Mustafizur Rahman|Back of a length ...|  null|     null|  true|      null|    null|49.5|   1|     null|\n",
      "|Bhuvneshwar Kumar| Mustafizur Rahman|Just 1 run off th...|  null|     null|  true|      null|    null|49.4|   1|     null|\n",
      "|         MS Dhoni| Mustafizur Rahman|OUT! No Dhoni mag...|     W|     3676|  true|      null|       1|49.3|   0|     null|\n",
      "|         MS Dhoni| Mustafizur Rahman|Another dot. Bang...|  null|     null|  true|      null|    null|49.2|   0|     null|\n",
      "|         MS Dhoni| Mustafizur Rahman|Good length ball ...|  null|     null|  true|      null|    null|49.1|   0|     null|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Good length ball ...|  null|     null|  true|      null|    null|48.6|   1|     null|\n",
      "|         MS Dhoni|Mohammad Saifuddin|FOUR! Dhoni rolli...|  null|     null|  true|         1|    null|48.5|   4|     null|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Slower delivery o...|  null|     null|  true|      null|    null|48.4|   0|     null|\n",
      "+-----------------+------------------+--------------------+------+---------+------+----------+--------+----+----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_column_data = data.drop('Batsman', 'Bowler', 'Id')\n",
    "drop_column_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Îç∞Ïù¥ÌÑ∞Ïùò ÌñâÍ≥º Ïó¥Ïùò ÏàòÎ•º ÏïÑÎùºÎ≥¥Ïûê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(drop_column_data.count() , len(drop_column_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringIndexer\n",
    "StringIndexerÎäî Î¨∏ÏûêÎ•º Ïπ¥ÌÖåÍ≥†Î¶¨(Ïà´Ïûê)Î°ú Î∞îÍøîÏ£ºÎäî Ìï®ÏàòÎã§.\n",
    "\n",
    "ÏòàÎ•ºÎì§Ïñ¥ Batsman_NameÏùÄ 20Í∞úÏùò stringÏúºÎ°ú ÏûÖÎ†•ÎêòÏñ¥ ÏûàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_column_data.select('Batsman_Name').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      Batsman_Name|\n",
      "+------------------+\n",
      "|    Mohammed Shami|\n",
      "| Bhuvneshwar Kumar|\n",
      "|          MS Dhoni|\n",
      "|    Dinesh Karthik|\n",
      "|      Rishabh Pant|\n",
      "|     Hardik Pandya|\n",
      "|       Virat Kohli|\n",
      "|          KL Rahul|\n",
      "|      Rohit Sharma|\n",
      "| Mustafizur Rahman|\n",
      "|     Rubel Hossain|\n",
      "|Mohammad Saifuddin|\n",
      "|  Mashrafe Mortaza|\n",
      "|     Sabbir Rahman|\n",
      "|   Shakib Al Hasan|\n",
      "|  Mosaddek Hossain|\n",
      "|         Liton Das|\n",
      "|   Mushfiqur Rahim|\n",
      "|     Soumya Sarkar|\n",
      "|       Tamim Iqbal|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_column_data.select('Batsman_Name').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ïù¥Îü∞ÏãùÏúºÎ°ú Î≤îÏ£ºÌôîÌïú Ïª¨ÎüºÏù¥ ÎßåÎì§Ïñ¥ÏßÑÎã§\n",
    "> ü§î Í∑ºÎç∞ Î¨¥Ïä®Í∏∞Ï§ÄÏúºÎ°ú indexÍ∞Ä Îß§Í≤®ÏßÄÎäîÍ±∞ÏßÄ ‚úî Count ÏàúÏù¥Îã§ ! Í∞ØÏàòÍ∞Ä Í∞ÄÏû• ÎßéÏùÄ Î≤îÏ£ºÍ∞Ä 0Ïù¥Îã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-----+\n",
      "|Batsman_Index|      Batsman_Name|count|\n",
      "+-------------+------------------+-----+\n",
      "|          0.0|      Rohit Sharma|   94|\n",
      "|          1.0|          KL Rahul|   93|\n",
      "|          2.0|   Shakib Al Hasan|   75|\n",
      "|          3.0|      Rishabh Pant|   43|\n",
      "|          4.0|Mohammad Saifuddin|   42|\n",
      "|          5.0|     Sabbir Rahman|   40|\n",
      "|          6.0|     Soumya Sarkar|   39|\n",
      "|          7.0|          MS Dhoni|   33|\n",
      "|          8.0|       Tamim Iqbal|   31|\n",
      "|          9.0|       Virat Kohli|   27|\n",
      "|         10.0|         Liton Das|   24|\n",
      "|         11.0|   Mushfiqur Rahim|   23|\n",
      "|         12.0|     Rubel Hossain|   11|\n",
      "|         13.0|    Dinesh Karthik|    9|\n",
      "|         14.0|  Mosaddek Hossain|    7|\n",
      "|         15.0|  Mashrafe Mortaza|    5|\n",
      "|         16.0| Bhuvneshwar Kumar|    4|\n",
      "|         17.0|     Hardik Pandya|    2|\n",
      "|         18.0|    Mohammed Shami|    2|\n",
      "|         19.0| Mustafizur Rahman|    1|\n",
      "+-------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Batsman_nameÏùÑ Î≤îÏ£ºÌôîÌïú Ïª¨Îüº Ïù¥Î¶Ñ -> Batsman_Index\n",
    "SI_batsman = StringIndexer(inputCol='Batsman_Name', outputCol='Batsman_Index')\n",
    "transform_data = SI_batsman.fit(drop_column_data).transform(drop_column_data)\n",
    "\n",
    "transform_data.select(\n",
    "    'Batsman_Index', 'Batsman_Name'\n",
    "    ).groupBy(\n",
    "    'Batsman_Index', 'Batsman_Name'\n",
    "    ).count(\n",
    "    ).sort(\n",
    "    'Batsman_Index'\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+------------------+------------+\n",
      "|     Batsman_Name|Batsman_Index|       Bowler_Name|Bowler_Index|\n",
      "+-----------------+-------------+------------------+------------+\n",
      "|   Mohammed Shami|         18.0| Mustafizur Rahman|         0.0|\n",
      "|Bhuvneshwar Kumar|         16.0| Mustafizur Rahman|         0.0|\n",
      "|   Mohammed Shami|         18.0| Mustafizur Rahman|         0.0|\n",
      "|Bhuvneshwar Kumar|         16.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "|Bhuvneshwar Kumar|         16.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0| Mustafizur Rahman|         0.0|\n",
      "|Bhuvneshwar Kumar|         16.0| Mustafizur Rahman|         0.0|\n",
      "|   Dinesh Karthik|         13.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0| Mustafizur Rahman|         0.0|\n",
      "|         MS Dhoni|          7.0|Mohammad Saifuddin|         8.0|\n",
      "+-----------------+-------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SI_bowler = StringIndexer(inputCol='Bowler_Name', outputCol='Bowler_Index')\n",
    "transform_data = SI_bowler.fit(transform_data).transform(transform_data)\n",
    "\n",
    "transform_data.select('Batsman_Name', 'Batsman_Index', 'Bowler_Name', 'Bowler_Index').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder\n",
    "OneHotEncoderÎäî Î≤îÏ£ºÌôîÎêú Í∞íÏùÑ (Î≤îÏ£º Í∞ØÏàò, [Î≤îÏ£º Í∞í], ?) Î°ú ÌëúÌòÑÌïòÎäî mapÏù¥Îã§.\n",
    "\n",
    "ÏòàÎ•ºÎì§Ïñ¥ Batsman_NameÏùÄ 20Í∞úÏùò stringÏúºÎ°ú ÏûÖÎ†•ÎêòÏñ¥ ÏûàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+---------------+-----+\n",
      "|      Batsman_Name|Batsman_Index|    Batsman_OHE|count|\n",
      "+------------------+-------------+---------------+-----+\n",
      "|      Rohit Sharma|          0.0| (19,[0],[1.0])|   94|\n",
      "|          KL Rahul|          1.0| (19,[1],[1.0])|   93|\n",
      "|   Shakib Al Hasan|          2.0| (19,[2],[1.0])|   75|\n",
      "|      Rishabh Pant|          3.0| (19,[3],[1.0])|   43|\n",
      "|Mohammad Saifuddin|          4.0| (19,[4],[1.0])|   42|\n",
      "|     Sabbir Rahman|          5.0| (19,[5],[1.0])|   40|\n",
      "|     Soumya Sarkar|          6.0| (19,[6],[1.0])|   39|\n",
      "|          MS Dhoni|          7.0| (19,[7],[1.0])|   33|\n",
      "|       Tamim Iqbal|          8.0| (19,[8],[1.0])|   31|\n",
      "|       Virat Kohli|          9.0| (19,[9],[1.0])|   27|\n",
      "|         Liton Das|         10.0|(19,[10],[1.0])|   24|\n",
      "|   Mushfiqur Rahim|         11.0|(19,[11],[1.0])|   23|\n",
      "|     Rubel Hossain|         12.0|(19,[12],[1.0])|   11|\n",
      "|    Dinesh Karthik|         13.0|(19,[13],[1.0])|    9|\n",
      "|  Mosaddek Hossain|         14.0|(19,[14],[1.0])|    7|\n",
      "|  Mashrafe Mortaza|         15.0|(19,[15],[1.0])|    5|\n",
      "| Bhuvneshwar Kumar|         16.0|(19,[16],[1.0])|    4|\n",
      "|     Hardik Pandya|         17.0|(19,[17],[1.0])|    2|\n",
      "|    Mohammed Shami|         18.0|(19,[18],[1.0])|    2|\n",
      "| Mustafizur Rahman|         19.0|     (19,[],[])|    1|\n",
      "+------------------+-------------+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create object and specify input and output column\n",
    "OHE = OneHotEncoder(inputCols=['Batsman_Index', 'Bowler_Index'],outputCols=['Batsman_OHE', 'Bowler_OHE'])\n",
    "\n",
    "# transform the data\n",
    "OHE_data = OHE.fit(transform_data).transform(transform_data)\n",
    "\n",
    "# view and transform the data\n",
    "OHE_data.select(\n",
    "    'Batsman_Name', 'Batsman_Index', 'Batsman_OHE'\n",
    "    ).groupBy(\n",
    "    'Batsman_Name', 'Batsman_Index', 'Batsman_OHE'\n",
    "    ).count(\n",
    "    ).sort(\n",
    "    'Batsman_Index'\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+------+---------+------+----------+--------+----+----+---------+-------------+------------+---------------+--------------+--------------------+\n",
      "|     Batsman_Name|       Bowler_Name|          Commentary|Detail|Dismissed|Isball|Isboundary|Iswicket|Over|Runs|Timestamp|Batsman_Index|Bowler_Index|    Batsman_OHE|    Bowler_OHE|              vector|\n",
      "+-----------------+------------------+--------------------+------+---------+------+----------+--------+----+----+---------+-------------+------------+---------------+--------------+--------------------+\n",
      "|   Mohammed Shami| Mustafizur Rahman|OUT! Bowled! 5-fe...|     W|    28994|  true|         0|       1|49.6|   0|     null|         18.0|         0.0|(19,[18],[1.0])|(11,[0],[1.0])|(36,[1,2,4,24,25]...|\n",
      "|Bhuvneshwar Kumar| Mustafizur Rahman|WIDE AND RUN OUT!...|  W+wd|     5132|  true|         0|       1|49.6|   1|     null|         16.0|         0.0|(19,[16],[1.0])|(11,[0],[1.0])|(36,[1,2,3,4,22,2...|\n",
      "|   Mohammed Shami| Mustafizur Rahman|Back of a length ...|  null|        0|  true|         0|       0|49.5|   1|     null|         18.0|         0.0|(19,[18],[1.0])|(11,[0],[1.0])|(36,[2,3,4,24,25]...|\n",
      "|Bhuvneshwar Kumar| Mustafizur Rahman|Just 1 run off th...|  null|        0|  true|         0|       0|49.4|   1|     null|         16.0|         0.0|(19,[16],[1.0])|(11,[0],[1.0])|(36,[2,3,4,22,25]...|\n",
      "|         MS Dhoni| Mustafizur Rahman|OUT! No Dhoni mag...|     W|     3676|  true|         0|       1|49.3|   0|     null|          7.0|         0.0| (19,[7],[1.0])|(11,[0],[1.0])|(36,[1,2,4,13,25]...|\n",
      "|         MS Dhoni| Mustafizur Rahman|Another dot. Bang...|  null|        0|  true|         0|       0|49.2|   0|     null|          7.0|         0.0| (19,[7],[1.0])|(11,[0],[1.0])|(36,[2,4,13,25],[...|\n",
      "|         MS Dhoni| Mustafizur Rahman|Good length ball ...|  null|        0|  true|         0|       0|49.1|   0|     null|          7.0|         0.0| (19,[7],[1.0])|(11,[0],[1.0])|(36,[2,4,13,25],[...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Good length ball ...|  null|        0|  true|         0|       0|48.6|   1|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[2,3,4,5,13,3...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|FOUR! Dhoni rolli...|  null|        0|  true|         1|       0|48.5|   4|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[0,2,3,4,5,13...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Slower delivery o...|  null|        0|  true|         0|       0|48.4|   0|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[2,4,5,13,33]...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Fuller on off, Dh...|  null|        0|  true|         0|       0|48.3|   0|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[2,4,5,13,33]...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|FOUR! Driven with...|  null|        0|  true|         1|       0|48.2|   4|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[0,2,3,4,5,13...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Good length ball ...|  null|        0|  true|         0|       0|48.1|   2|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[2,3,4,5,13,3...|\n",
      "|Bhuvneshwar Kumar| Mustafizur Rahman|Slower bouncer to...|  null|        0|  true|         0|       0|47.6|   0|     null|         16.0|         0.0|(19,[16],[1.0])|(11,[0],[1.0])|(36,[2,4,22,25],[...|\n",
      "|         MS Dhoni| Mustafizur Rahman|Length delivery a...|  null|        0|  true|         0|       0|47.5|   1|     null|          7.0|         0.0| (19,[7],[1.0])|(11,[0],[1.0])|(36,[2,3,4,13,25]...|\n",
      "|         MS Dhoni| Mustafizur Rahman|Good length ball ...|  null|        0|  true|         0|       0|47.4|   0|     null|          7.0|         0.0| (19,[7],[1.0])|(11,[0],[1.0])|(36,[2,4,13,25],[...|\n",
      "|Bhuvneshwar Kumar| Mustafizur Rahman|Good length ball ...|  null|        0|  true|         0|       0|47.3|   1|     null|         16.0|         0.0|(19,[16],[1.0])|(11,[0],[1.0])|(36,[2,3,4,22,25]...|\n",
      "|   Dinesh Karthik| Mustafizur Rahman|OUT! Caught! Kart...|     W|     3632|  true|         0|       1|47.2|   0|     null|         13.0|         0.0|(19,[13],[1.0])|(11,[0],[1.0])|(36,[1,2,4,19,25]...|\n",
      "|         MS Dhoni| Mustafizur Rahman|On the pads, Dhon...|  null|        0|  true|         0|       0|47.1|   1|     null|          7.0|         0.0| (19,[7],[1.0])|(11,[0],[1.0])|(36,[2,3,4,13,25]...|\n",
      "|         MS Dhoni|Mohammad Saifuddin|Almost a calamity...|  null|        0|  true|         0|       0|46.6|   1|     null|          7.0|         8.0| (19,[7],[1.0])|(11,[8],[1.0])|(36,[2,3,4,5,13,3...|\n",
      "+-----------------+------------------+--------------------+------+---------+------+----------+--------+----+----+---------+-------------+------------+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# specify the input and output columns of the vector assembler\n",
    "assembler = VectorAssembler(inputCols=['Isboundary',\n",
    "                                       'Iswicket',\n",
    "                                       'Over',\n",
    "                                       'Runs',\n",
    "                                       'Batsman_Index',\n",
    "                                       'Bowler_Index',\n",
    "                                       'Batsman_OHE',\n",
    "                                       'Bowler_OHE'],\n",
    "                           outputCol='vector')\n",
    "\n",
    "fill_null_data = OHE_data.fillna(0)\n",
    "\n",
    "final_data = assembler.transform(fill_null_data)\n",
    "\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+\n",
      "| id|category_1|category_2|\n",
      "+---+----------+----------+\n",
      "|  1|      L101|         R|\n",
      "|  2|      L201|         C|\n",
      "|  3|      D111|         R|\n",
      "|  4|      F210|         R|\n",
      "|  5|      D110|         C|\n",
      "+---+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# create a sample dataframe\n",
    "sample_df = spark.createDataFrame([\n",
    "    (1, 'L101', 'R'),\n",
    "    (2, 'L201', 'C'),\n",
    "    (3, 'D111', 'R'),\n",
    "    (4, 'F210', 'R'),\n",
    "    (5, 'D110', 'C')\n",
    "], ['id', 'category_1', 'category_2'])\n",
    "\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+----------------+----------------+--------------+\n",
      "| id|category_1|category_2|category_1_index|category_2_index|category_2_OHE|\n",
      "+---+----------+----------+----------------+----------------+--------------+\n",
      "|  1|      L101|         R|             3.0|             0.0| (1,[0],[1.0])|\n",
      "|  2|      L201|         C|             4.0|             1.0|     (1,[],[])|\n",
      "|  3|      D111|         R|             1.0|             0.0| (1,[0],[1.0])|\n",
      "|  4|      F210|         R|             2.0|             0.0| (1,[0],[1.0])|\n",
      "|  5|      D110|         C|             0.0|             1.0|     (1,[],[])|\n",
      "+---+----------+----------+----------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define stage 1 : transform the column category_1 to numeric\n",
    "stage_1 = StringIndexer(inputCol= 'category_1', outputCol= 'category_1_index')\n",
    "# define stage 2 : transform the column category_2 to numeric\n",
    "stage_2 = StringIndexer(inputCol= 'category_2', outputCol= 'category_2_index')\n",
    "# define stage 3 : one hot encode the numeric category_2 column\n",
    "stage_3 = OneHotEncoder(inputCols=['category_2_index'], outputCols=['category_2_OHE'])\n",
    "\n",
    "# setup the pipeline\n",
    "pipeline = Pipeline(stages=[stage_1, stage_2, stage_3])\n",
    "\n",
    "# fit the pipeline model and transform the data as defined\n",
    "pipeline_model = pipeline.fit(sample_df)\n",
    "sample_df_updated = pipeline_model.transform(sample_df)\n",
    "\n",
    "# view the transformed data\n",
    "sample_df_updated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Algorithm\n",
    "- Classification\n",
    "  - Logistic regression\n",
    "  - Decision tree\n",
    "  - Random forest\n",
    "  - Gradient-bossted tree\n",
    "  - ...\n",
    "\n",
    "- Regression\n",
    "  - Linear regression \n",
    "  - Decision tree regression\n",
    "  - Random forest regression\n",
    "  - Gradient-boosted regression\n",
    "  - ... \n",
    "  \n",
    "[Ï∞∏Í≥†](https://spark.apache.org/docs/latest/ml-classification-regression.html#classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+-----+\n",
      "|feature_1|feature_2|feature_3|feature_4|label|\n",
      "+---------+---------+---------+---------+-----+\n",
      "|      2.0|        A|      S10|       40|  1.0|\n",
      "|      1.0|        X|      E10|       25|  1.0|\n",
      "|      4.0|        X|      S20|       10|  0.0|\n",
      "|      3.0|        Z|      S10|       20|  0.0|\n",
      "|      4.0|        A|      E10|       30|  1.0|\n",
      "|      2.0|        Z|      S10|       40|  0.0|\n",
      "|      5.0|        X|      D10|       10|  1.0|\n",
      "+---------+---------+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# create a sample dataframe with 4 features and 1 label column\n",
    "sample_data_train = spark.createDataFrame([\n",
    "    (2.0, 'A', 'S10', 40, 1.0),\n",
    "    (1.0, 'X', 'E10', 25, 1.0),\n",
    "    (4.0, 'X', 'S20', 10, 0.0),\n",
    "    (3.0, 'Z', 'S10', 20, 0.0),\n",
    "    (4.0, 'A', 'E10', 30, 1.0),\n",
    "    (2.0, 'Z', 'S10', 40, 0.0),\n",
    "    (5.0, 'X', 'D10', 10, 1.0),\n",
    "], ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'label'])\n",
    "\n",
    "# view the data\n",
    "sample_data_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[2.0,0.0,1.0,1.0,...|  1.0|[-18.956871848873...|[5.84972108437629...|       1.0|\n",
      "|[1.0,1.0,0.0,0.0,...|  1.0|[-20.158269476976...|[1.75944137519440...|       1.0|\n",
      "|(7,[0,1,6],[4.0,1...|  0.0|[18.0148602858563...|[0.99999998499466...|       0.0|\n",
      "|(7,[0,3,6],[3.0,1...|  0.0|[24.5051237560211...|[0.99999999997721...|       0.0|\n",
      "|[4.0,0.0,1.0,0.0,...|  1.0|[-50.288624611182...|[1.44519958724341...|       1.0|\n",
      "|(7,[0,3,6],[2.0,1...|  0.0|[18.3280841853910...|[0.99999998902980...|       0.0|\n",
      "|[5.0,1.0,0.0,0.0,...|  1.0|[-17.986823547341...|[1.54319845459293...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define stage 1: transform the column feature_2 to numeric\n",
    "stage_1 = StringIndexer(inputCol= 'feature_2', outputCol= 'feature_2_index')\n",
    "\n",
    "# define stage 2: transform the column feature_3 to numeric\n",
    "stage_2 = StringIndexer(inputCol= 'feature_3', outputCol= 'feature_3_index')\n",
    "\n",
    "# define stage 3: one hot encode the numeric versions of feature 2 and 3 generated from stage 1 and stage 2\n",
    "stage_3 = OneHotEncoder(inputCols=[stage_1.getOutputCol(), stage_2.getOutputCol()], \n",
    "                                 outputCols= ['feature_2_encoded', 'feature_3_encoded'])\n",
    "\n",
    "# define stage 4: create a vector of all the features required to train the logistic regression model \n",
    "stage_4 = VectorAssembler(inputCols=['feature_1', 'feature_2_encoded', 'feature_3_encoded', 'feature_4'],\n",
    "                          outputCol='features')\n",
    "\n",
    "# define stage 5: logistic regression model                          \n",
    "stage_5 = LogisticRegression(featuresCol='features',labelCol='label')\n",
    "\n",
    "# setup the pipeline\n",
    "regression_pipeline = Pipeline(stages=[stage_1, stage_2, stage_3, stage_4, stage_5])\n",
    "\n",
    "# fit the pipeline for the trainind data\n",
    "model = regression_pipeline.fit(sample_data_train)\n",
    "# transform the data\n",
    "sample_data_train = model.transform(sample_data_train)\n",
    "\n",
    "# view some of the columns generated\n",
    "sample_data_train.select('features', 'label', 'rawPrediction', 'probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|(7,[0,3,6],[3.0,1...|[21.9361235191363...|[0.99999999970265...|       0.0|\n",
      "|[1.0,1.0,0.0,0.0,...|[-19.516019417755...|[3.34426325212871...|       1.0|\n",
      "|(7,[0,2,6],[4.0,1...|[-22.297362790363...|[2.07194574533260...|       1.0|\n",
      "|[3.0,0.0,1.0,1.0,...|[-12.779832278243...|[2.81700837724637...|       1.0|\n",
      "|[4.0,1.0,0.0,0.0,...|[-24.163863117971...|[3.20455394170236...|       1.0|\n",
      "|(7,[0,4,6],[1.0,1...|[-22.543286459710...|[1.62022409523199...|       1.0|\n",
      "|[4.0,0.0,1.0,1.0,...|[-10.456293062940...|[2.87658445082044...|       1.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a sample data without the labels\n",
    "sample_data_test = spark.createDataFrame([\n",
    "    (3.0, 'Z', 'S10', 40),\n",
    "    (1.0, 'X', 'E10', 20),\n",
    "    (4.0, 'A', 'S20', 10),\n",
    "    (3.0, 'A', 'S10', 20),\n",
    "    (4.0, 'X', 'D10', 30),\n",
    "    (1.0, 'Z', 'E10', 20),\n",
    "    (4.0, 'A', 'S10', 30),\n",
    "], ['feature_1', 'feature_2', 'feature_3', 'feature_4'])\n",
    "\n",
    "# transform the data using the pipeline\n",
    "sample_data_test = model.transform(sample_data_test)\n",
    "\n",
    "# see the prediction on the test data\n",
    "sample_data_test.select('features', 'rawPrediction', 'probability', 'prediction').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
